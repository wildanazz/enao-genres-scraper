name: Schedule Scraping Job

on:
  schedule:
    # This will run the workflow at midnight (00:00 UTC) every day.
    - cron: "0 0 * * *"

  # Allows manual triggering of the workflow
  workflow_dispatch:

jobs:
  scrape-job:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.8"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install psycopg2-binary selenium tqdm python-dotenv pandas

      - name: Set up Google Chrome and ChromeDriver
        uses: browser-actions/setup-chrome@v1

      - name: Run scraping script
        env:
          GITHUB_ACTIONS: "true"
        run: |
          python ./scraper/genres_scraper.py
          python ./visualizer/genres_visualizer.py

      - name: Commit and push updated data to the repository
        run: |
          git config --global user.name "GitHub Actions"
          git config --global user.email "actions@github.com"

          # Add the updated data file(s) to the commit
          git add data/

          # Commit changes if there are any
          git diff --cached --quiet || git commit -m "Update scraping results"

          # Push the changes back to the repository
          git push
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
